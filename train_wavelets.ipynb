{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models import EEGformer  # Import the EEGformer model\n",
    "#from model_fft import EEGformer\n",
    "import resampy\n",
    "\n",
    "# Define device and enable Data Parallelism if multiple GPUs are available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check if multiple GPUs are available\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Using {num_gpus} GPUs\")\n",
    "sampling_rate = 177          # Example sampling rate (samples per second)\n",
    "duration = 3                  # Duration in seconds\n",
    "samples_to_extract = sampling_rate * duration  # Total samples for 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom Dataset for loading .npz files\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".npz\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        npz_data = np.load(file_path)\n",
    "\n",
    "        data = resampy.resample(npz_data['data'], sr_orig=npz_data['frequency'], sr_new=sampling_rate)\n",
    "        label = npz_data['label']\n",
    "\n",
    "        num_channels = data.shape[0]\n",
    "        time_steps = data.shape[1]\n",
    "\n",
    "        if samples_to_extract > time_steps:\n",
    "            raise ValueError(f\"Data only has {time_steps} time steps, but {samples_to_extract} are required.\")\n",
    "\n",
    "        data = data[0, :samples_to_extract]  # Select first channel and slice for 3 seconds\n",
    "        data = np.expand_dims(data, axis=0)   # Shape: (1, samples_to_extract)\n",
    "\n",
    "        data_tensor = torch.tensor(data.astype(np.float32))\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return data_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the processed .npz files\n",
    "train_dir = \"/home/hira/eeg/nmt_events/train\"\n",
    "val_dir = \"/home/hira/eeg/nmt_events/eval\"\n",
    "test_dir = \"/home/hira/eeg/EEG_crops_per_channel/test\"\n",
    "model_saving_path = \"/home/hira/eeg/EEG_crops_per_channel/model/\"\n",
    "model_name = \"eeg_former_v2\"\n",
    "\n",
    "# Initialize the datasets and dataloaders\n",
    "batch_size = 8 * num_gpus  # Adjust batch size according to available GPUs\n",
    "train_dataset = EEGDataset(data_dir=train_dir)\n",
    "val_dataset = EEGDataset(data_dir=val_dir)\n",
    "test_dataset = EEGDataset(data_dir=test_dir)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=10, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=10, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=10, pin_memory=True)\n",
    "\n",
    "# Parameters\n",
    "input_channels = 1\n",
    "num_cls = 2\n",
    "kernel_size = 10\n",
    "num_blocks = 3\n",
    "num_heads_rtm = 6\n",
    "num_heads_stm = 6\n",
    "num_heads_ttm = 11\n",
    "num_submatrices = 12\n",
    "CF_second = 2\n",
    "\n",
    "# Create a dummy input with shape expected by the model\n",
    "sample_input = torch.randn(8, samples_to_extract, input_channels).to(device)\n",
    "print(sample_input.shape)\n",
    "\n",
    "# Initialize the model\n",
    "model = EEGformer(input=sample_input, num_cls=num_cls, input_channels=input_channels,\n",
    "                  kernel_size=kernel_size, num_blocks=num_blocks, num_heads_RTM=num_heads_rtm,\n",
    "                  num_heads_STM=num_heads_stm, num_heads_TTM=num_heads_ttm,\n",
    "                  num_submatrices=num_submatrices, CF_second=CF_second)\n",
    "\n",
    "\n",
    "\n",
    "# Use Data Parallelism if multiple GPUs are available\n",
    "if num_gpus > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# Load the saved model state\n",
    "model.load_state_dict(torch.load(model_saving_path + \"eeg_former_v2\" + \".pth\"))\n",
    "\n",
    "# Move the model to GPU(s)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.000005, weight_decay=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Continue training\n",
    "start_epoch = 95  # Start from the next epoch\n",
    "num_epochs = 100  # Total number of epochs to train (25 more epochs)\n",
    "best_val_acc = 82.75   \n",
    " # Set to the last saved validation accuracy\n",
    "model.train()\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10  # Number of epochs to wait for improvement (3 in this case)\n",
    "counter = 0  # Counter for epochs without improvement\n",
    "\n",
    "for epoch_idx in range(start_epoch, num_epochs):\n",
    "    # --- Training Phase ---\n",
    "    total_train_loss = 0.0\n",
    "    train_true = []\n",
    "    train_preds = []\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch_idx + 1}/{num_epochs}] - Training\")\n",
    "    with tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Training Epoch {epoch_idx + 1}\") as train_bar:\n",
    "        for batch_idx, (inputs, labels) in train_bar:\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update loss\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "            train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Update the progress bar with current loss\n",
    "            train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Compute training metrics\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_accuracy = accuracy_score(train_true, train_preds) * 100\n",
    "    train_precision = precision_score(train_true, train_preds, average='macro', zero_division=0)\n",
    "    train_recall = recall_score(train_true, train_preds, average='macro', zero_division=0)\n",
    "    train_f1 = f1_score(train_true, train_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"Training Loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1-score: {train_f1:.4f}\")\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    val_true = []\n",
    "    val_preds = []\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch_idx + 1}/{num_epochs}] - Validation\")\n",
    "    with torch.no_grad():\n",
    "        with tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc=f\"Validation Epoch {epoch_idx + 1}\") as val_bar:\n",
    "            for batch_idx, (inputs, labels) in val_bar:\n",
    "                if inputs.shape[0] != batch_size:\n",
    "                    continue\n",
    "\n",
    "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "                val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "                val_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_accuracy = accuracy_score(val_true, val_preds) * 100\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # --- Save the model if validation accuracy improved ---\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        torch.save(model.state_dict(), model_saving_path + model_name + \".pth\")\n",
    "        print(f\"Model saved at epoch {epoch_idx + 1} with validation accuracy: {val_accuracy:.2f}%\")\n",
    "        counter = 0  # Reset counter when improvement happens\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"Early stopping counter: {counter} out of {patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break #stop the training loop.\n",
    "\n",
    "    model.train()  # Switch back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model weights\n",
    "state_dict = torch.load(model_saving_path + model_name + \".pth\")\n",
    "\n",
    "# If trained with DataParallel, remove \"module.\" prefix\n",
    "if \"module.\" in list(state_dict.keys())[0]:  \n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_state_dict[k.replace(\"module.\", \"\")] = v\n",
    "    state_dict = new_state_dict  # Update state dict\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)  # Move to GPU\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "total_test_loss = 0.0\n",
    "test_true = []\n",
    "test_preds = []\n",
    "\n",
    "print(\"\\nTesting Phase\")\n",
    "with torch.no_grad():\n",
    "    with tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc=\"Testing\") as test_bar:\n",
    "        for batch_idx, (inputs, labels) in test_bar:\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_true.extend(labels.cpu().numpy())\n",
    "            test_preds.extend(predicted.cpu().numpy())\n",
    "            \n",
    "            test_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "test_accuracy = accuracy_score(test_true, test_preds) * 100\n",
    "test_precision = precision_score(test_true, test_preds, average='macro', zero_division=0)\n",
    "test_recall = recall_score(test_true, test_preds, average='macro', zero_division=0)\n",
    "test_f1 = f1_score(test_true, test_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1-score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
