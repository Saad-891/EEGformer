{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models import EEGformer  # Import the EEGformer model\n",
    "import resampy\n",
    "\n",
    "# Define device and enable Data Parallelism if multiple GPUs are available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check if multiple GPUs are available\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Using {num_gpus} GPUs\")\n",
    "sampling_rate = 177          # Example sampling rate (samples per second)\n",
    "duration = 3                  # Duration in seconds\n",
    "samples_to_extract = sampling_rate * duration  # Total samples for 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom Dataset for loading .npz files\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".npz\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        npz_data = np.load(file_path)\n",
    "\n",
    "        data = resampy.resample(npz_data['data'], sr_orig=npz_data['frequency'], sr_new=sampling_rate)\n",
    "        label = npz_data['label']\n",
    "\n",
    "        num_channels = data.shape[0]\n",
    "        time_steps = data.shape[1]\n",
    "\n",
    "        if samples_to_extract > time_steps:\n",
    "            raise ValueError(f\"Data only has {time_steps} time steps, but {samples_to_extract} are required.\")\n",
    "\n",
    "        data = data[0, :samples_to_extract]  # Select first channel and slice for 3 seconds\n",
    "        data = np.expand_dims(data, axis=0)   # Shape: (1, samples_to_extract)\n",
    "\n",
    "        data_tensor = torch.tensor(data.astype(np.float32))\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return data_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 531, 1])\n"
     ]
    }
   ],
   "source": [
    "# Paths to the processed .npz files\n",
    "train_dir = \"/home/hira/eeg/nmt_events/train\"\n",
    "val_dir = \"/home/hira/eeg/nmt_events/eval\"\n",
    "test_dir = \"/home/hira/eeg/EEG_crops_per_channel/test\"\n",
    "model_saving_path = \"/home/hira/eeg/EEG_crops_per_channel/model/\"\n",
    "model_name = \"eeg_former_v2\"\n",
    "\n",
    "# Initialize the datasets and dataloaders\n",
    "batch_size = 8 * num_gpus  # Adjust batch size according to available GPUs\n",
    "train_dataset = EEGDataset(data_dir=train_dir)\n",
    "val_dataset = EEGDataset(data_dir=val_dir)\n",
    "test_dataset = EEGDataset(data_dir=test_dir)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=10, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=10, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=10, pin_memory=True)\n",
    "\n",
    "# Parameters\n",
    "input_channels = 1\n",
    "num_cls = 2\n",
    "kernel_size = 10\n",
    "num_blocks = 3\n",
    "num_heads_rtm = 6\n",
    "num_heads_stm = 6\n",
    "num_heads_ttm = 11\n",
    "num_submatrices = 12\n",
    "CF_second = 2\n",
    "\n",
    "# Create a dummy input with shape expected by the model\n",
    "sample_input = torch.randn(8, samples_to_extract, input_channels).to(device)\n",
    "print(sample_input.shape)\n",
    "\n",
    "# Initialize the model\n",
    "model = EEGformer(input=sample_input, num_cls=num_cls, input_channels=input_channels,\n",
    "                  kernel_size=kernel_size, num_blocks=num_blocks, num_heads_RTM=num_heads_rtm,\n",
    "                  num_heads_STM=num_heads_stm, num_heads_TTM=num_heads_ttm,\n",
    "                  num_submatrices=num_submatrices, CF_second=CF_second)\n",
    "\n",
    "\n",
    "\n",
    "# Use Data Parallelism if multiple GPUs are available\n",
    "if num_gpus > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# Load the saved model state\n",
    "model.load_state_dict(torch.load(model_saving_path + \"eeg_former_v2\" + \".pth\"))\n",
    "\n",
    "# Move the model to GPU(s)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [36/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 5987/5987 [3:31:26<00:00,  2.12s/it, loss=0.384]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4302, Accuracy: 87.81%\n",
      "Precision: 0.8821, Recall: 0.8745, F1-score: 0.8765\n",
      "\n",
      "Epoch [36/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 36: 100%|██████████| 1120/1120 [11:36<00:00,  1.61it/s, loss=0.434]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4814, Accuracy: 82.41%\n",
      "Early stopping counter: 1 out of 10\n",
      "\n",
      "Epoch [37/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 37: 100%|██████████| 5987/5987 [3:32:27<00:00,  2.13s/it, loss=0.416]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4298, Accuracy: 87.86%\n",
      "Precision: 0.8825, Recall: 0.8751, F1-score: 0.8771\n",
      "\n",
      "Epoch [37/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 37: 100%|██████████| 1120/1120 [11:36<00:00,  1.61it/s, loss=0.435]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4807, Accuracy: 82.51%\n",
      "Early stopping counter: 2 out of 10\n",
      "\n",
      "Epoch [38/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 38: 100%|██████████| 5987/5987 [3:32:59<00:00,  2.13s/it, loss=0.374]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4294, Accuracy: 87.96%\n",
      "Precision: 0.8835, Recall: 0.8761, F1-score: 0.8781\n",
      "\n",
      "Epoch [38/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 38: 100%|██████████| 1120/1120 [11:36<00:00,  1.61it/s, loss=0.434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4803, Accuracy: 82.61%\n",
      "Model saved at epoch 38 with validation accuracy: 82.61%\n",
      "\n",
      "Epoch [39/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39: 100%|██████████| 5987/5987 [3:33:25<00:00,  2.14s/it, loss=0.39]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4289, Accuracy: 88.01%\n",
      "Precision: 0.8842, Recall: 0.8765, F1-score: 0.8786\n",
      "\n",
      "Epoch [39/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 39: 100%|██████████| 1120/1120 [11:37<00:00,  1.61it/s, loss=0.44] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4809, Accuracy: 82.41%\n",
      "Early stopping counter: 1 out of 10\n",
      "\n",
      "Epoch [40/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 40: 100%|██████████| 5987/5987 [3:29:42<00:00,  2.10s/it, loss=0.444]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4289, Accuracy: 87.99%\n",
      "Precision: 0.8839, Recall: 0.8764, F1-score: 0.8784\n",
      "\n",
      "Epoch [40/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 40: 100%|██████████| 1120/1120 [11:36<00:00,  1.61it/s, loss=0.441]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4805, Accuracy: 82.52%\n",
      "Early stopping counter: 2 out of 10\n",
      "\n",
      "Epoch [41/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 41: 100%|██████████| 5987/5987 [3:30:13<00:00,  2.11s/it, loss=0.374]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4293, Accuracy: 87.94%\n",
      "Precision: 0.8835, Recall: 0.8759, F1-score: 0.8779\n",
      "\n",
      "Epoch [41/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 41: 100%|██████████| 1120/1120 [11:38<00:00,  1.60it/s, loss=0.442]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4797, Accuracy: 82.59%\n",
      "Early stopping counter: 3 out of 10\n",
      "\n",
      "Epoch [42/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 42: 100%|██████████| 5987/5987 [3:31:28<00:00,  2.12s/it, loss=0.566]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4289, Accuracy: 87.94%\n",
      "Precision: 0.8834, Recall: 0.8759, F1-score: 0.8779\n",
      "\n",
      "Epoch [42/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 42: 100%|██████████| 1120/1120 [11:31<00:00,  1.62it/s, loss=0.434]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4800, Accuracy: 82.57%\n",
      "Early stopping counter: 4 out of 10\n",
      "\n",
      "Epoch [43/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 43: 100%|██████████| 5987/5987 [3:32:17<00:00,  2.13s/it, loss=0.333]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4291, Accuracy: 87.95%\n",
      "Precision: 0.8833, Recall: 0.8760, F1-score: 0.8780\n",
      "\n",
      "Epoch [43/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 43: 100%|██████████| 1120/1120 [11:39<00:00,  1.60it/s, loss=0.441]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4803, Accuracy: 82.54%\n",
      "Early stopping counter: 5 out of 10\n",
      "\n",
      "Epoch [44/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 44: 100%|██████████| 5987/5987 [3:29:52<00:00,  2.10s/it, loss=0.434]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4289, Accuracy: 88.00%\n",
      "Precision: 0.8841, Recall: 0.8765, F1-score: 0.8785\n",
      "\n",
      "Epoch [44/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 44: 100%|██████████| 1120/1120 [12:11<00:00,  1.53it/s, loss=0.443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4799, Accuracy: 82.61%\n",
      "Model saved at epoch 44 with validation accuracy: 82.61%\n",
      "\n",
      "Epoch [45/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45: 100%|██████████| 5987/5987 [3:23:27<00:00,  2.04s/it, loss=0.404]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4289, Accuracy: 87.98%\n",
      "Precision: 0.8837, Recall: 0.8764, F1-score: 0.8783\n",
      "\n",
      "Epoch [45/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 45: 100%|██████████| 1120/1120 [12:11<00:00,  1.53it/s, loss=0.441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4795, Accuracy: 82.62%\n",
      "Model saved at epoch 45 with validation accuracy: 82.62%\n",
      "\n",
      "Epoch [46/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46: 100%|██████████| 5987/5987 [3:22:20<00:00,  2.03s/it, loss=0.448]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4292, Accuracy: 87.96%\n",
      "Precision: 0.8837, Recall: 0.8760, F1-score: 0.8780\n",
      "\n",
      "Epoch [46/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 46: 100%|██████████| 1120/1120 [12:04<00:00,  1.55it/s, loss=0.446]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4799, Accuracy: 82.57%\n",
      "Early stopping counter: 1 out of 10\n",
      "\n",
      "Epoch [47/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 47: 100%|██████████| 5987/5987 [3:24:36<00:00,  2.05s/it, loss=0.397]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4287, Accuracy: 87.96%\n",
      "Precision: 0.8835, Recall: 0.8761, F1-score: 0.8781\n",
      "\n",
      "Epoch [47/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 47: 100%|██████████| 1120/1120 [12:09<00:00,  1.54it/s, loss=0.435]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4799, Accuracy: 82.61%\n",
      "Early stopping counter: 2 out of 10\n",
      "\n",
      "Epoch [48/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 48: 100%|██████████| 5987/5987 [3:27:40<00:00,  2.08s/it, loss=0.445]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4285, Accuracy: 88.04%\n",
      "Precision: 0.8842, Recall: 0.8770, F1-score: 0.8790\n",
      "\n",
      "Epoch [48/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 48: 100%|██████████| 1120/1120 [11:36<00:00,  1.61it/s, loss=0.443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4801, Accuracy: 82.55%\n",
      "Early stopping counter: 3 out of 10\n",
      "\n",
      "Epoch [49/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49: 100%|██████████| 5987/5987 [3:33:58<00:00,  2.14s/it, loss=0.476]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4287, Accuracy: 88.00%\n",
      "Precision: 0.8839, Recall: 0.8765, F1-score: 0.8785\n",
      "\n",
      "Epoch [49/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 49: 100%|██████████| 1120/1120 [11:33<00:00,  1.62it/s, loss=0.449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4794, Accuracy: 82.65%\n",
      "Model saved at epoch 49 with validation accuracy: 82.65%\n",
      "\n",
      "Epoch [50/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50: 100%|██████████| 5987/5987 [3:35:28<00:00,  2.16s/it, loss=0.435]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4287, Accuracy: 87.98%\n",
      "Precision: 0.8837, Recall: 0.8764, F1-score: 0.8784\n",
      "\n",
      "Epoch [50/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 50: 100%|██████████| 1120/1120 [13:02<00:00,  1.43it/s, loss=0.448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4796, Accuracy: 82.57%\n",
      "Early stopping counter: 1 out of 10\n",
      "\n",
      "Epoch [51/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 51: 100%|██████████| 5987/5987 [4:25:02<00:00,  2.66s/it, loss=0.366]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4284, Accuracy: 88.08%\n",
      "Precision: 0.8845, Recall: 0.8774, F1-score: 0.8793\n",
      "\n",
      "Epoch [51/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 51: 100%|██████████| 1120/1120 [11:47<00:00,  1.58it/s, loss=0.451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4791, Accuracy: 82.72%\n",
      "Model saved at epoch 51 with validation accuracy: 82.72%\n",
      "\n",
      "Epoch [52/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52: 100%|██████████| 5987/5987 [3:52:16<00:00,  2.33s/it, loss=0.417]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4285, Accuracy: 88.01%\n",
      "Precision: 0.8842, Recall: 0.8766, F1-score: 0.8786\n",
      "\n",
      "Epoch [52/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 52: 100%|██████████| 1120/1120 [15:26<00:00,  1.21it/s, loss=0.45] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4796, Accuracy: 82.65%\n",
      "Early stopping counter: 1 out of 10\n",
      "\n",
      "Epoch [53/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53: 100%|██████████| 5987/5987 [3:54:53<00:00,  2.35s/it, loss=0.369]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4282, Accuracy: 88.04%\n",
      "Precision: 0.8843, Recall: 0.8770, F1-score: 0.8790\n",
      "\n",
      "Epoch [53/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 53: 100%|██████████| 1120/1120 [11:40<00:00,  1.60it/s, loss=0.438]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4793, Accuracy: 82.59%\n",
      "Early stopping counter: 2 out of 10\n",
      "\n",
      "Epoch [54/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 54: 100%|██████████| 5987/5987 [3:33:23<00:00,  2.14s/it, loss=0.416]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4279, Accuracy: 88.13%\n",
      "Precision: 0.8852, Recall: 0.8779, F1-score: 0.8798\n",
      "\n",
      "Epoch [54/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 54: 100%|██████████| 1120/1120 [12:00<00:00,  1.56it/s, loss=0.442]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4793, Accuracy: 82.65%\n",
      "Early stopping counter: 3 out of 10\n",
      "\n",
      "Epoch [55/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 55: 100%|██████████| 5987/5987 [4:10:05<00:00,  2.51s/it, loss=0.387]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4282, Accuracy: 88.07%\n",
      "Precision: 0.8847, Recall: 0.8772, F1-score: 0.8792\n",
      "\n",
      "Epoch [55/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 55: 100%|██████████| 1120/1120 [11:38<00:00,  1.60it/s, loss=0.449]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4793, Accuracy: 82.65%\n",
      "Early stopping counter: 4 out of 10\n",
      "\n",
      "Epoch [56/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 56: 100%|██████████| 5987/5987 [4:03:35<00:00,  2.44s/it, loss=0.493]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4281, Accuracy: 88.07%\n",
      "Precision: 0.8847, Recall: 0.8773, F1-score: 0.8793\n",
      "\n",
      "Epoch [56/100] - Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 56: 100%|██████████| 1120/1120 [15:32<00:00,  1.20it/s, loss=0.454]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4796, Accuracy: 82.56%\n",
      "Early stopping counter: 5 out of 10\n",
      "\n",
      "Epoch [57/100] - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 57:  13%|█▎        | 799/5987 [34:43<3:50:31,  2.67s/it, loss=0.403]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Continue training\n",
    "start_epoch = 57  # Start from the next epoch\n",
    "num_epochs = 100  # Total number of epochs to train (25 more epochs)\n",
    "best_val_acc = 82.72 # Set to the last saved validation accuracy\n",
    "model.train()\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10  # Number of epochs to wait for improvement (3 in this case)\n",
    "counter = 0  # Counter for epochs without improvement\n",
    "\n",
    "for epoch_idx in range(start_epoch, num_epochs):\n",
    "    # --- Training Phase ---\n",
    "    total_train_loss = 0.0\n",
    "    train_true = []\n",
    "    train_preds = []\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch_idx + 1}/{num_epochs}] - Training\")\n",
    "    with tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Training Epoch {epoch_idx + 1}\") as train_bar:\n",
    "        for batch_idx, (inputs, labels) in train_bar:\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update loss\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "            train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Update the progress bar with current loss\n",
    "            train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Compute training metrics\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_accuracy = accuracy_score(train_true, train_preds) * 100\n",
    "    train_precision = precision_score(train_true, train_preds, average='macro', zero_division=0)\n",
    "    train_recall = recall_score(train_true, train_preds, average='macro', zero_division=0)\n",
    "    train_f1 = f1_score(train_true, train_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"Training Loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1-score: {train_f1:.4f}\")\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    val_true = []\n",
    "    val_preds = []\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch_idx + 1}/{num_epochs}] - Validation\")\n",
    "    with torch.no_grad():\n",
    "        with tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc=f\"Validation Epoch {epoch_idx + 1}\") as val_bar:\n",
    "            for batch_idx, (inputs, labels) in val_bar:\n",
    "                if inputs.shape[0] != batch_size:\n",
    "                    continue\n",
    "\n",
    "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "                val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "                val_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_accuracy = accuracy_score(val_true, val_preds) * 100\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # --- Save the model if validation accuracy improved ---\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        torch.save(model.state_dict(), model_saving_path + model_name + \".pth\")\n",
    "        print(f\"Model saved at epoch {epoch_idx + 1} with validation accuracy: {val_accuracy:.2f}%\")\n",
    "        counter = 0  # Reset counter when improvement happens\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"Early stopping counter: {counter} out of {patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break #stop the training loop.\n",
    "\n",
    "    model.train()  # Switch back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# existing_model_path = model_saving_path + model_name + '.pth'\n",
    "# print(existing_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import torch\n",
    "\n",
    "# #... your existing code...\n",
    "\n",
    "# # Path to your existing model weights file\n",
    "# existing_model_path = model_saving_path + model_name + \".pth\"\n",
    "\n",
    "# # Path to the new file where you want to copy the weights\n",
    "# new_model_path = model_saving_path + model_name + \"_25epochs_backup.pth\"  # Or any other descriptive name\n",
    "\n",
    "# # Copy the file\n",
    "# shutil.copyfile(existing_model_path, new_model_path)\n",
    "\n",
    "#... continue with your training code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model weights\n",
    "state_dict = torch.load(model_saving_path + model_name + \".pth\")\n",
    "\n",
    "# If trained with DataParallel, remove \"module.\" prefix\n",
    "if \"module.\" in list(state_dict.keys())[0]:  \n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_state_dict[k.replace(\"module.\", \"\")] = v\n",
    "    state_dict = new_state_dict  # Update state dict\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)  # Move to GPU\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "total_test_loss = 0.0\n",
    "test_true = []\n",
    "test_preds = []\n",
    "\n",
    "print(\"\\nTesting Phase\")\n",
    "with torch.no_grad():\n",
    "    with tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc=\"Testing\") as test_bar:\n",
    "        for batch_idx, (inputs, labels) in test_bar:\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_true.extend(labels.cpu().numpy())\n",
    "            test_preds.extend(predicted.cpu().numpy())\n",
    "            \n",
    "            test_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "test_accuracy = accuracy_score(test_true, test_preds) * 100\n",
    "test_precision = precision_score(test_true, test_preds, average='macro', zero_division=0)\n",
    "test_recall = recall_score(test_true, test_preds, average='macro', zero_division=0)\n",
    "test_f1 = f1_score(test_true, test_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1-score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braindecode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
